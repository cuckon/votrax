import os
import subprocess
import hashlib
import logging
import asyncio
from functools import lru_cache
from typing import Optional
from pathlib import Path

import requests

from fastapi import FastAPI
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles


MAX_FILES = 500
MP3_FOLDER = Path('./audio_files')
REGION = os.getenv('AZ_REGION')
HEADERS = {
    'Ocp-Apim-Subscription-Key': os.getenv('AZ_TOKEN'),
    'Content-Type': 'application/ssml+xml',
    'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3',
    'User-Agent': 'curl',
}

app = FastAPI()
app.mount('/static', StaticFiles(directory='static'), name='static')


def purge_files():
    """Keep the number of files within `MAX_FILES`."""
    audio_files = list(MP3_FOLDER.iterdir())
    n_audio_files = len(audio_files)
    if n_audio_files <= MAX_FILES:
        return

    audio_files.sort(key=os.path.getmtime, reverse=True)
    for i in range(MAX_FILES, n_audio_files):
        audio_files[i].unlink()


@lru_cache()
def get_voice_list():
    url = f'https://{REGION}.tts.speech.microsoft.com/cognitiveservices/voices/list'
    info = requests.get(url, headers=HEADERS).json()

    keys = ['ShortName', 'Gender', 'StyleList', 'LocalName']
    return [
        {k:i[k] for k in keys if k in i }
        for i in info if i['Locale'] == 'zh-CN'
    ]


def play_mp3(path):
    subprocess.Popen(['mpg123', '-q', path])


def hashed_file_name(text:str):
    """Generate a proper mp3 file name by hashing the text."""
    return hashlib.md5(text.encode('utf-8')).hexdigest() + '.mp3'


def _get_gender_by_name(name):
    for i in get_voice_list():
        if i['ShortName'] == name:
            return i['Gender']
    return 'Female'


def _azure_synthesis(text, name, style):
    voice_list = get_voice_list()
    gender = _get_gender_by_name(name)
    raw = f"""
    <speak xmlns="http://www.w3.org/2001/10/synthesis"
        xmlns:mstts="http://www.w3.org/2001/mstts"
        xmlns:emo="http://www.w3.org/2009/10/emotionml"
        version="1.0" xml:lang="en-US"
    >
        <voice xml:lang='zh-CN' xml:gender='{gender}' name='{name}'>
        <mstts:express-as style='{style}' >
            {text}
        </mstts:express-as>
        </voice>
    </speak>""".encode()

    # https://portal.azure.com/#@cuckonsgmail.onmicrosoft.com/resource/subscriptions/81e0d15b-786f-4a9a-a36c-818f32416dad/resourcegroups/Resource01/providers/Microsoft.CognitiveServices/accounts/Votrax/overview

    url = f'https://{REGION}.tts.speech.microsoft.com/cognitiveservices/v1'
    r = requests.post(url, data=raw, headers=HEADERS)
    return r.content


async def text_to_mp3(text:str, name, style) -> Path:
    """Convert text to mp3 file."""
    if not text:
        return

    if not MP3_FOLDER.exists():
        MP3_FOLDER.mkdir()

    path = MP3_FOLDER / hashed_file_name(text + name + style)
    if path.exists():
        path.touch()
        return path

    result = _azure_synthesis(text, name, style)

    path.write_bytes(result)
    purge_files()
    return path

    logging.error('Failed to convert text:' + result)


async def make_html(payload):
    return f'''
    <head><title>æœºå™¨çŒ«å¹¿æ’­ç«™</title></head>
    <body>
        <div>
            {payload}
        </div>
        <hr>
        <div>
            ğŸ¤—ç»™æœºå™¨çŒ«è½¬è´¦ï¼Œæ¢æ›´å¤§çš„å–‡å­:<br><br>
            <img src="/static/qrcode.png" width="160" height="160">
        </div>

    </body>
    '''


async def convert_and_play(text, name, style):
    mp3_path = await text_to_mp3(text, name, style)
    if mp3_path:
        play_mp3(str(mp3_path))
    return mp3_path


@app.get('/v1/{text}', response_class=HTMLResponse)
async def speak(
        text: str,
        name: Optional[str]='zh-CN-XiaoxiaoNeural',
        style: Optional[str]='affectionate',
    ):
    """Main entrance."""
    res = await asyncio.gather(
        convert_and_play(text, name, style),
        make_html(f'ğŸ”Šå·²å¹¿æ’­: "<B>{text}</B>"'),
    )

    return res[1]



@app.get('/v1')
async def get_list_api():
    """Get available parameters."""
    return get_voice_list()


@app.get('/list', response_class=HTMLResponse)
async def get_list():
    """Get available parameters."""
    from json2html import json2html
    simplified = get_voice_list()

    html = json2html.convert(json=simplified)
    return await make_html(html)


@app.get('/', response_class=HTMLResponse)
async def help():
    """Get available parameters."""
    html = '''
    <h1>æœºå™¨çŒ«å¹¿æ’­ç«™</h1>
    <p>v1.0.1 2021.07.04
    <div><img src="/static/speaker.jpg"></div>
    <p>ä»»æ„æµè§ˆå™¨ç›´æ¥è®¿é—®ç½‘å€å³å¯å¹¿æ’­æ–‡å­—ã€‚å¯ç”¨äºå¼ºæé†’ã€å¹¿æ’­æ‰¾äººç­‰æƒ…æ™¯ã€‚
    <p>å¯ç”¨èŒƒå›´ä¸ºæ‰€æœ‰å†…ç½‘çš„è®¾å¤‡ï¼Œæ¯”å¦‚ğŸ’»ç”µè„‘ã€ğŸ“±æ‰‹æœºã€ğŸ‘©â€ğŸ’»iPadã€‚
    <p>ç›®å‰å–‡å­çš„ç‰©ç†å®ä½“ä½äº: æ­å·ä¸€æœŸB6F-B45ã€‚
    <p>âš ï¸<b>å¹¿æ’­æºæš‚æ—¶ä¸è®¾é™ï¼ŒåŠåŒ¿åï¼ˆå¿…è¦æ—¶åå°å¯è·Ÿè¸ªï¼‰ã€‚è¯·éµçºªå®ˆæ³•ï¼Œå‹¿å¹¿æ’­ä¸è¯¥å¹¿æ’­çš„å†…å®¹ã€‚</b>
    <hr>
    <h2>ä½¿ç”¨èŒƒä¾‹</h2>
    <p><a href="javascript:void(0)">http://10.240.154.195:8000/v1/å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡</a><br>
    ğŸ”Šæ’­æ”¾"å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡"
    <p><a href="javascript:void(0)">http://10.240.154.195:8000/v1/å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡?name=zh-CN-YunyeNeural</a><br>
    ğŸ”Šæ’­æ”¾"å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡"ï¼Œä½¿ç”¨â€œäº‘é‡â€çš„å£°éŸ³ã€‚
    <p><a href="javascript:void(0)">http://10.240.154.195:8000/v1/å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡?style=angry</a><br>
    ğŸ”Šæ’­æ”¾"å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡"ï¼Œä½¿ç”¨ç”Ÿæ°”çš„è¯­è°ƒã€‚
    <p><a href="javascript:void(0)">http://10.240.154.195:8000/v1/å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡?name=zh-CN-YunyeNeural&style=angry</a><br>
    ğŸ”Šæ’­æ”¾"å‘¨æ°ä¼¦çœ‹ä¸€çœ¼æ³¡æ³¡"ï¼Œä½¿ç”¨â€œäº‘é‡â€çš„å£°éŸ³ï¼Œé…åˆç”Ÿæ°”çš„è¯­è°ƒã€‚
    <h2>å¯ç”¨å£°éŸ³å’Œè¯­è°ƒå‚è€ƒ</h2>
    <p>åœ¨<a href="/list">æ­¤é¡µé¢</a>æŸ¥çœ‹åˆ—è¡¨ã€‚
    <p>åœ¨<a href="https://azure.microsoft.com/zh-cn/services/cognitive-services/text-to-speech/">å¾®è½¯ Azureå®˜æ–¹</a>
    å¯è¯•å¬.
    '''
    return await make_html(html)
